for example while computers have been relatively successful at playing chess for many years notably the computer deep blue was able to defeat the reigning world chess champion garry kasparov in 1996 the game of go was considered much harder it wasn t until reinforcement learning techniques were used in 2015 that the program alphago was finally able to beat a professional human go player here we use deep q learning to train an agent to learn the arcade game lunar lander a game where the goal is to steer a landing module and successfully land it on the surface of the moon . this included the daily price opening closing high and low of the stock . by letting hard and soft correspond to the amount we invest in the stock market on a given week and not to the number of shares we ensure that our model is independent of the average price of the stock our model just cares about how the stock price fluctuates from week to week and not the absolute price of the stock . thus q should satisfy the optimal bellman equation where s is the state after taking action a from s and is the discount factor intuitively it parametrizes how much we value future versus current reward for deep q learning we use a neural network to learn the q function . for the lunar lander model we used a fully connected neural network of shape input . ii . the model is demonstrated to be rather risk averse but can master long term investment strategy with reasonably volatile stocks future directions shot term vs long term in our data split there is a mismatch as we are training on approximately 5 years of data and trying to test the agent on 10 weeks of data . 