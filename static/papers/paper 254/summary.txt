because different sonic levels can be used for the training and test sets this dataset is also be useful to see whether or not our algorithm lends itself well to our method of iterative training across experiments . 1 . that is it takes a frame as input and maps it to a distribution in a lower dimensional space in our case using a 4 layer convolutional neural network and a 200 dimensional encoding space . lstms maintain a gated memory representation across different items in a sequence with its updated memory accessible to the next state . the loss used for the generator was partially inspired by the loss used in a vae accounting for both the likelihood of the predicted next frame 2 and an adversarial loss corresponding to how effectively it tricked the discriminator . initially an interesting issue came up we were at the time letting the anticipator choose moves every time it ran since it went through all of the possible actions but often not moving had the same reward as the controller making its move since the controller would eventually accomplish whatever the best action accomplished . one accidental effect was that the anticipator accidentally created short sighted loops if in alert mode like repeatedly hitting a 10 point bumper . for our initial experimental round we use the jerk method to perform rollouts . the iterative architecture then uses policies generated from the previous experimental round as rollouts for the next experimental round which should improve the training of both the vae and the gan as they will be training on frames that score higher balanced with some exploration . we rewrote the procedure to be iterative and to reuse previous policies during rollouts as well as adding gan capacity and some features to action selection in the code . 