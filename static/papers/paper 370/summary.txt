we present results and analyses of our experimentation with several different methods for predicting the terminal punctuation of a sentence the terminal punctuation or end mark of a sentence provides important semantic and syntactical information about a sentence . additionally to maximize the number of question mark and exclamation point samples we needed to ensure that we could extract standalone sentences within quotations eg how are you . our definition for a sentence was a sequence of space separated words starting with a capital word ending with an end mark and unbroken by any single or double quotation marks . we made this decision because of the valuable structural information these non terminal punctuation provide about the sentence they are in we merged this tokenized data and then vectorized each tokenized sentence in a number of different ways including binary vectors bag of word vectors and tfidf transformed bag of word vectors . random guessing would given an unfairly low benchmark as the vast majority of the data belongs to the period class we started by looking at the results of guessing all periods one metric it scored very poorly on however was macro averaged even weighted f1 score macro f1 . both of these models took so long to train that we trained them on a random subsample of the train set but they then predicted all periods . this is not significant enough for us to conclude that a random forest is the optimal model for this problem we found not surprisingly that all of our models had stronger performance on qmark sentences than expoint sentences . this matches our intuition questions can be identified by the presence of question words ex who when will while exclamatory sentences are more easily confused with declarative sentences . jonathan worked on the logistic regression and baseline models . 