since 2009 real time bidding rtb has become popular in online display advertising 1 when a user visits an ad supported site each ad placement triggers an ad request to the ad exchange . since the company data is confidential and there is no public dataset available for ads auction simulation the link of our previous choice ipinyou dataset. to be more similar to the real world we use time of day pattern to simulate the traffic . since we generate a random amount of impressions in each time slot to mimic the actual traffic the environment input is entirely different every time . the action space is discretized into a finite number of bins we experimented with 10 12 15 and 20 then found 10 performs best . as to state space we tried both discretized and continuous and found their results are comparable so we used continuous version for simplicity . the dqn is implemented with experience replay for the discounted cost we set discount factor to 0 99 and we used td 0 to compute the loss for optimization we used adam . in the beginning we attempted to use a series of neural network layers and its result turned out very unstable . to avoid overfitting we simplified the architecture of the neural network in code using only one hidden layer with 16 neurons . for ddpg the action space is continuous so that we won t see the stairs like pacing signal curve as in dqn . however our algorithm still needs improvement because the training is not stable sometimes the network can generate results like in. overall we explored the possibility of applying reinforcement learning to ads budget pacing problem . on simulated ads auction data our dqn algorithm shows promising results comparing with the baseline algorithm . 3 try alternative cost function and regularization . 